stages:
  - build
  - train
  - package
  - notify

variables:
  AWS_DEFAULT_REGION: "us-east-1"
  SAGEMAKER_ROLE_ARN: "arn:aws:iam::${AWS_ACCOUNT_ID}:role/SageMakerExecutionRole"
  S3_BUCKET: "ml-training-data-${AWS_ACCOUNT_ID}"
  GITLAB_ARTIFACTS_BUCKET: "gitlab-server-production-artifacts-9a9f2e1f"
  GITLAB_RELEASES_BUCKET: "gitlab-server-production-releases-438fe745"
  PYTHON_VERSION: "3.8"

image: python:${PYTHON_VERSION}

before_script:
  - pip install --upgrade pip
  - pip install boto3 sagemaker requests
  - echo "Pipeline triggered by commit hash"
  - echo "Loading environment variables..."
  - if [ -f .env ]; then source .env; fi
  - echo "Environment setup completed"

build_job:
  stage: build
  script:
    - echo "Building and preparing environment..."
    - python --version
    - pwd
    - ls -la
    - echo "Dependencies installed."
    - mkdir -p .venv
    - echo "Virtual environment placeholder created"
  artifacts:
    paths:
      - .venv/
    expire_in: 1 hour

train_job:
  stage: train
  script:
    - echo "Starting SageMaker training job..."
    - pwd
    - echo "Available files:"
    - ls -la
    - echo "Python files:"
    - ls -la *.py || echo "No Python files found"
    - echo "Environment variables:"
    - echo "CI_PROJECT_NAME is $CI_PROJECT_NAME"
    - echo "CI_COMMIT_SHORT_SHA is $CI_COMMIT_SHORT_SHA"
    - echo "AWS_ACCOUNT_ID is $AWS_ACCOUNT_ID"
    - echo "SAGEMAKER_ROLE_ARN is $SAGEMAKER_ROLE_ARN"
    - echo "S3_BUCKET is $S3_BUCKET"
    - echo "Checking if train.py exists"
    - test -f train.py && echo "train.py exists" || echo "train.py not found"
    - |
      if [ -f train.py ]; then
        echo "Running training script..."
        python train.py --job-name "$CI_PROJECT_NAME-$CI_COMMIT_SHORT_SHA" --role-arn "$SAGEMAKER_ROLE_ARN" --s3-bucket "$S3_BUCKET" --instance-type ml.m5.large --max-runtime 3600 --num-round 100 --max-depth 6 --eta 0.3 --objective reg:squarederror
      else
        echo "train.py not found, skipping training"
        exit 1
      fi
  artifacts:
    paths:
      - training_output/
      - test-results.xml
    expire_in: 1 day

package_job:
  stage: package
  script:
    - echo "Creating and uploading artifact package..."
    - echo "Available files:"
    - ls -la
    - echo "Checking for create_zip_package.py"
    - test -f create_zip_package.py && echo "create_zip_package.py exists" || echo "create_zip_package.py not found"
    - echo "Checking for training_output directory"
    - test -d training_output && echo "training_output exists" || echo "training_output not found"
    - |
      if [ -f create_zip_package.py ]; then
        echo "Running packaging script..."
        python create_zip_package.py --zip-name "$CI_PROJECT_NAME-$CI_COMMIT_SHORT_SHA.zip" --release-type "training-artifact" --commit-id "$CI_COMMIT_SHORT_SHA" --training-output training_output/
      else
        echo "create_zip_package.py not found, skipping packaging"
        exit 1
      fi
  dependencies:
    - train_job
  artifacts:
    paths:
      - "*.zip"
    expire_in: 1 week

notify_job:
  stage: notify
  script:
    - echo "Sending pipeline completion notification..."
    - echo "Available files:"
    - ls -la
    - echo "Checking for send_notification.py"
    - test -f send_notification.py && echo "send_notification.py exists" || echo "send_notification.py not found"
    - |
      if [ -f send_notification.py ]; then
        echo "Running notification script..."
        python send_notification.py --pipeline-status "$CI_PIPELINE_STATUS" --project-name "$CI_PROJECT_NAME" --pipeline-url "$CI_PIPELINE_URL"
      else
        echo "send_notification.py not found, skipping notification"
        echo "Notification step completed (mock)"
      fi
  when: always
  dependencies:
    - package_job